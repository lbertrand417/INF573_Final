{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSize(image, face_landmarks, INDEXES):\n",
    "    '''\n",
    "    This function calculates the height and width of a face part utilizing its landmarks.\n",
    "    Args:\n",
    "        image:          The image of person(s) whose face part size is to be calculated.\n",
    "        face_landmarks: The detected face landmarks of the person whose face part size is to \n",
    "                        be calculated.\n",
    "        INDEXES:        The indexes of the face part landmarks, whose size is to be calculated.\n",
    "    Returns:\n",
    "        width:     The calculated width of the face part of the face whose landmarks were passed.\n",
    "        height:    The calculated height of the face part of the face whose landmarks were passed.\n",
    "        landmarks: An array of landmarks of the face part whose size is calculated.\n",
    "    '''\n",
    "    \n",
    "    # Retrieve the height and width of the image.\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # Initialize a list to store the landmarks of the face part.\n",
    "    landmarks = []\n",
    "    \n",
    "    # Iterate over the indexes of the landmarks of the face part. \n",
    "    for INDEX in INDEXES:\n",
    "        \n",
    "        # Append the landmark into the list.\n",
    "        landmarks.append([int(face_landmarks.landmark[INDEX].x * image_width),\n",
    "                               int(face_landmarks.landmark[INDEX].y * image_height)])\n",
    "    \n",
    "    # Calculate the width and height of the face part.\n",
    "    # TODO: Transform it to take into account the sheearing --> find the 3D boundinx box and project \n",
    "    # the closest face to the screen\n",
    "    _, _, width, height = cv2.boundingRect(np.array(landmarks))\n",
    "    \n",
    "    # Convert the list of landmarks of the face part into a numpy array.\n",
    "    landmarks = np.array(landmarks)\n",
    "    \n",
    "    # Return the calculated width height and the landmarks of the face part.\n",
    "    return width, height, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isOpen(image, face_mesh_results, face_part, threshold=5):\n",
    "    '''\n",
    "    This function checks whether the eye or mouth of the person(s) is open, \n",
    "    utilizing its facial landmarks.\n",
    "    Args:\n",
    "        image:             The image of person(s) whose an eye or mouth is to be checked.\n",
    "        face_mesh_results: The output of the facial landmarks detection on the image.\n",
    "        face_part:         The name of the face part that is required to check: MOUTH, RIGHT EYE, LEFT EYE\n",
    "        threshold:         The threshold value used to check the isOpen condition.\n",
    "    Returns:\n",
    "        status:       A dictionary containing isOpen statuses of the face part of all the \n",
    "                      detected faces.  \n",
    "    '''\n",
    "    \n",
    "    # Retrieve the height and width of the image.\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    \n",
    "    # Create a dictionary to store the isOpen status of the face part of all the detected faces.\n",
    "    status={}\n",
    "    \n",
    "    # Check if the face part is mouth.\n",
    "    if face_part == 'MOUTH':\n",
    "        \n",
    "        # Get the indexes of the mouth.\n",
    "        INDEXES = mp_face_mesh.FACEMESH_LIPS\n",
    "        \n",
    "    # Check if the face part is left eye.    \n",
    "    elif face_part == 'LEFT EYE':\n",
    "        \n",
    "        # Get the indexes of the left eye.\n",
    "        INDEXES = mp_face_mesh.FACEMESH_LEFT_EYE\n",
    "    \n",
    "    # Check if the face part is right eye.    \n",
    "    elif face_part == 'RIGHT EYE':\n",
    "        \n",
    "        # Get the indexes of the right eye.\n",
    "        INDEXES = mp_face_mesh.FACEMESH_RIGHT_EYE \n",
    "    \n",
    "    # Otherwise return nothing.\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    # Convert the indexes of the landmarks of the face part into a list.\n",
    "    # TODO: Rewrite it in a more natural way OR undestand it + Is it necessaray to create it as a list?\n",
    "    INDEXES_LIST = set(list(itertools.chain(*INDEXES)))\n",
    "    \n",
    "    # Iterate over the found faces.\n",
    "    for face_no, face_landmarks in enumerate(face_mesh_results.multi_face_landmarks):\n",
    "        \n",
    "         # Get the height of the face part.\n",
    "        _, height, _ = getSize(image, face_landmarks, INDEXES_LIST)\n",
    "        \n",
    "         # Get the height of the whole face.\n",
    "        face_oval = set(list(itertools.chain(*mp_face_mesh.FACEMESH_FACE_OVAL)))\n",
    "        _, face_height, _ = getSize(image, face_landmarks, face_oval)\n",
    "        \n",
    "        # Check if the face part is open.\n",
    "        if (height/face_height)*100 > threshold:\n",
    "            \n",
    "            # Set status of the face part to open.\n",
    "            status[face_no] = 'OPEN'\n",
    "        \n",
    "        # Otherwise.\n",
    "        else:\n",
    "            # Set status of the face part to close.\n",
    "            status[face_no] = 'CLOSE'\n",
    "    \n",
    "    # Otherwise\n",
    "    else:\n",
    "        \n",
    "        # Return the output image and the isOpen statuses of the face part of each detected face.\n",
    "        return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(image, filter_img, face_landmarks, face_part, INDEXES):\n",
    "    '''\n",
    "    This function will overlay a filter image over a face part of a person in the image/frame.\n",
    "    Args:\n",
    "        image:          The image of a person on which the filter image will be overlayed.\n",
    "        filter_img:     The filter image that is needed to be overlayed on the image of the person.\n",
    "        face_landmarks: The facial landmarks of the person in the image.\n",
    "        face_part:      The name of the face part on which the filter image will be overlayed.\n",
    "        INDEXES:        The indexes of landmarks of the face part.\n",
    "        display:        A boolean value that is if set to true the function displays \n",
    "                        the annotated image and returns nothing.\n",
    "    Returns:\n",
    "        annotated_image: The image with the overlayed filter on the top of the specified face part.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the image to overlay filter image on.\n",
    "    annotated_image = image.copy()\n",
    "    \n",
    "    # Errors can come when it resizes the filter image to a too small or a too large size .\n",
    "    # So use a try block to avoid application crashing.\n",
    "    try:\n",
    "            \n",
    "        # Get the width and height of filter image.\n",
    "        filter_img_height, filter_img_width, _  = filter_img.shape\n",
    "\n",
    "\n",
    "        # Check if the face part is mouth.\n",
    "        if face_part == 'MOUTH':\n",
    "            # Get the height of the face part on which we will overlay the filter image.\n",
    "            _, face_part_height, landmarks = getSize(image, face_landmarks, INDEXES)\n",
    "\n",
    "            # Specify the height to which the filter image is required to be resized.\n",
    "            # 2.5 can be changed depending on the size of the filter we want\n",
    "            # This allows the filter to be bigger/smaller depending on both the size of the eye and the size of the aperture\n",
    "            # of the eye\n",
    "            required_height = int(face_part_height*1.5)\n",
    "\n",
    "            # Resize the filter image to the required height, while keeping the aspect ratio constant. \n",
    "            resized_filter_img = cv2.resize(filter_img, (int(filter_img_width*(required_height/filter_img_height)),\n",
    "                                                         required_height))\n",
    "\n",
    "            # Get the new width and height of filter image.\n",
    "            filter_img_height, filter_img_width, _  = resized_filter_img.shape\n",
    "            \n",
    "            # Calculate the center of the face part.\n",
    "            center = landmarks.mean(axis=0).astype(\"int\")\n",
    "\n",
    "            # Calculate the location where the mouth filter will be placed.  \n",
    "            # Location is the position of the upper left corner of the filter image\n",
    "            location = (int(center[0] - filter_img_width / 2), int(center[1]))\n",
    "\n",
    "        # Otherwise if the face part is an eye.\n",
    "        elif face_part == 'LEFT EYE' or face_part == 'RIGHT EYE':\n",
    "            \n",
    "            # Get the height of the face part on which we will overlay the filter image.\n",
    "            _, face_part_height, landmarks = getSize(image, face_landmarks, INDEXES)\n",
    "\n",
    "            # Specify the height to which the filter image is required to be resized.\n",
    "            # 2.5 can be changed depending on the size of the filter we want\n",
    "            # This allows the filter to be bigger/smaller depending on both the size of the eye and the size of the aperture\n",
    "            # of the eye\n",
    "            required_height = int(face_part_height*2.5)\n",
    "\n",
    "            # Resize the filter image to the required height, while keeping the aspect ratio constant. \n",
    "            resized_filter_img = cv2.resize(filter_img, (int(filter_img_width*(required_height/filter_img_height)),\n",
    "                                                         required_height))\n",
    "\n",
    "            # Get the new width and height of filter image.\n",
    "            filter_img_height, filter_img_width, _  = resized_filter_img.shape\n",
    "            \n",
    "            # Calculate the center of the face part.\n",
    "            center = landmarks.mean(axis=0).astype(\"int\")\n",
    "\n",
    "            # Calculate the location where the eye filter image will be placed.  \n",
    "            # Location is the position of the upper left corner of the filter image\n",
    "            location = (int(center[0]-filter_img_width/2), int(center[1]-filter_img_height/2))\n",
    "            \n",
    "        elif face_part == 'FOREHEAD':\n",
    "                        \n",
    "            # Get the height of the face part on which we will overlay the filter image.\n",
    "            face_part_width, _, landmarks = getSize(image, face_landmarks, INDEXES)\n",
    "            \n",
    "            # Specify the height to which the filter image is required to be resized.\n",
    "            # 2.5 can be changed depending on the size of the filter we want\n",
    "            # This allows the filter to be bigger/smaller depending on both the size of the eye and the size of the aperture\n",
    "            # of the eye\n",
    "            required_width = int(face_part_width*2.5)\n",
    "\n",
    "            # Resize the filter image to the required height, while keeping the aspect ratio constant. \n",
    "            resized_filter_img = cv2.resize(filter_img, (required_width,\n",
    "                                                         int(filter_img_height*(required_width/filter_img_width))))\n",
    "\n",
    "            # Get the new width and height of filter image.\n",
    "            filter_img_height, filter_img_width, _  = resized_filter_img.shape\n",
    "            \n",
    "            # Calculate the center of the face part.\n",
    "            center = landmarks.mean(axis=0).astype(\"int\")\n",
    "\n",
    "            # Calculate the location where the eye filter image will be placed.  \n",
    "            # Location is the position of the upper left corner of the filter image\n",
    "            location = (int(center[0]-filter_img_width/2), int(center[1]-filter_img_height))\n",
    "            \n",
    "            \n",
    "\n",
    "        # Retrieve the region of interest from the image where the filter image will be placed.\n",
    "        ROI = image[location[1]: location[1] + filter_img_height,\n",
    "                    location[0]: location[0] + filter_img_width]\n",
    "        \n",
    "        # Convert the image to grayscale and apply the threshold to get the invert mask of the filter image.\n",
    "        # We obtain a filter_img_mask with 255 in black area (pixel < 25) and 0 in other areas\n",
    "        # This is used to put the black background in transparent\n",
    "        _, filter_img_mask = cv2.threshold(cv2.cvtColor(resized_filter_img, cv2.COLOR_BGR2GRAY),\n",
    "                                           25, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Perform Bitwise-AND operation. \n",
    "        # Black-out the area of the filter in ROI\n",
    "        resultant_image = cv2.bitwise_and(ROI, ROI, mask=filter_img_mask)\n",
    "\n",
    "        # Add the resultant image and the resized filter image.\n",
    "        # This will update the pixel values of the resultant image at the indexes where \n",
    "        # pixel values are zero, to the pixel values of the filter image.\n",
    "        resultant_image = cv2.add(resultant_image, resized_filter_img)\n",
    "\n",
    "        # Update the image's region of interest with resultant image.\n",
    "        annotated_image[location[1]: location[1] + filter_img_height,\n",
    "                        location[0]: location[0] + filter_img_width] = resultant_image\n",
    "            \n",
    "    # Catch and handle the error(s).\n",
    "    except Exception as e:\n",
    "        pass\n",
    "            \n",
    "    # Return the annotated image.\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe face mesh class.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Setup the face landmarks function for videos.\n",
    "# TODO: Here works for only one face --> Make it work for multiple faces (see overlay call in main function)\n",
    "face_mesh_videos = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, \n",
    "                                         min_detection_confidence=0.5,min_tracking_confidence=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the mediapipe drawing class.\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Initialize the mediapipe drawing styles class.\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "\n",
    "# Set camera resolution\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Create named window for resizing purposes.\n",
    "cv2.namedWindow('Face Filter', cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Read the left and right eyes images.\n",
    "# TODO: Create an interactive window to let the user select the wanted filters\n",
    "left_eye = cv2.imread('data/left_eye_cupcake.png')\n",
    "right_eye = cv2.imread('data/right_eye_cupcake.png')\n",
    "\n",
    "crown = cv2.imread('data/crown.png')\n",
    "\n",
    "# Initialize the VideoCapture object to read from the smoke animation video stored in the disk.\n",
    "# TODO: Same as for images --> Create a dictionary to store all images and videos?\n",
    "animation = cv2.VideoCapture('data/rainbow_animation1.mp4')\n",
    "\n",
    "# Set the smoke animation video frame counter to zero.\n",
    "animation_frame_counter = 0\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "    \n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "    \n",
    "    # Check if frame is not read properly then continue to the next iteration to read\n",
    "    # the next frame.\n",
    "    if not ok:\n",
    "        continue\n",
    "        \n",
    "    # Read a frame from smoke animation video\n",
    "    _, animation_frame = animation.read()\n",
    "    \n",
    "    # Increment the smoke animation video frame counter.\n",
    "    animation_frame_counter += 1\n",
    "    \n",
    "    # Check if the current frame is the last frame of the animation video.\n",
    "    if animation_frame_counter == animation.get(cv2.CAP_PROP_FRAME_COUNT):     \n",
    "        \n",
    "        # Set the current frame position to first frame to restart the video.\n",
    "        animation.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "        # Set the animation video frame counter to zero.\n",
    "        animation_frame_counter = 0\n",
    "    \n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Perform the facial landmarks detection on the image, after converting it into RGB format.\n",
    "    # TODO: check why we have to put ::-1\n",
    "    face_mesh_results = face_mesh_videos.process(frame[:,:,::-1])\n",
    "    \n",
    "    output_image = frame.copy()\n",
    "    \n",
    "    # Check if facial landmarks are found.\n",
    "    if face_mesh_results.multi_face_landmarks:        \n",
    "        # Get the mouth isOpen status of the person in the frame.\n",
    "        mouth_status = isOpen(frame, face_mesh_results, 'MOUTH', \n",
    "                                     threshold=15)\n",
    "        \n",
    "        # Get the left eye isOpen status of the person in the frame.\n",
    "        left_eye_status = isOpen(frame, face_mesh_results, 'LEFT EYE', \n",
    "                                        threshold=4.5)\n",
    "        \n",
    "        # Get the right eye isOpen status of the person in the frame.\n",
    "        right_eye_status = isOpen(frame, face_mesh_results, 'RIGHT EYE', \n",
    "                                         threshold=4.5)\n",
    "        \n",
    "        # Iterate over the found faces.\n",
    "        for face_num, face_landmarks in enumerate(face_mesh_results.multi_face_landmarks):\n",
    "            \n",
    "            # Check if the left eye of the face is open.\n",
    "            if left_eye_status[face_num] == 'OPEN':\n",
    "                # Convert the indexes of the landmarks of the face part into a list.\n",
    "                # TODO: Rewrite it in a more natural way OR undestand it + Is it necessaray to create it as a list?\n",
    "                left_eye_landmarks = set(list(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\n",
    "                \n",
    "                # Overlay the left eye image on the frame at the appropriate location.\n",
    "                # TODO: I don't know if this will work with multiple faces because of mp_face_mesh.FACEMESH_LEFT_EYE \n",
    "                # (same for the 2 other) because it considers all meshes and not only one mesh --> Adapt it\n",
    "                # to multiple meshes if it doesn't work\n",
    "                frame = overlay(frame, left_eye, face_landmarks,\n",
    "                                'LEFT EYE', left_eye_landmarks)\n",
    "            \n",
    "            # Check if the right eye of the face is open.\n",
    "            if right_eye_status[face_num] == 'OPEN':\n",
    "                \n",
    "                # Convert the indexes of the landmarks of the face part into a list.\n",
    "                # TODO: Rewrite it in a more natural way OR undestand it + Is it necessaray to create it as a list?\n",
    "                right_eye_landmarks = set(list(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))\n",
    "                \n",
    "                # Overlay the right eye image on the frame at the appropriate location.\n",
    "                frame = overlay(frame, right_eye, face_landmarks,\n",
    "                                'RIGHT EYE', right_eye_landmarks)\n",
    "                            \n",
    "            lips_landmarks = set(list(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))\n",
    "            # Check if the mouth of the face is open.\n",
    "            if mouth_status[face_num] == 'OPEN':\n",
    "                \n",
    "                # Convert the indexes of the landmarks of the face part into a list.\n",
    "                # TODO: Rewrite it in a more natural way OR undestand it + Is it necessaray to create it as a list?\n",
    "                lips_landmarks = set(list(itertools.chain(*mp_face_mesh.FACEMESH_LIPS)))\n",
    "                \n",
    "                # Overlay the smoke animation on the frame at the appropriate location.\n",
    "                frame = overlay(frame, animation_frame, face_landmarks, \n",
    "                                'MOUTH', lips_landmarks)\n",
    "                \n",
    "            forehead_landmarks = [103, 67, 109, 10, 338, 297, 332]\n",
    "            frame = overlay(frame, crown, face_landmarks, 'FOREHEAD', forehead_landmarks)\n",
    "            \n",
    "    \n",
    "    # Display the frame.\n",
    "    cv2.imshow('Face Filter', frame)\n",
    "    \n",
    "    # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.\n",
    "    k = cv2.waitKey(1) & 0xFF    \n",
    "    \n",
    "    # Check if 'ESC' is pressed and break the loop.\n",
    "    if(k == 27):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture Object and close the windows.                  \n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF573",
   "language": "python",
   "name": "inf573"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
